{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/AkarshNagaraj/opt/anaconda3/lib/python3.7/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['contour', 'resize']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "#Performing filtering operation\n",
    "def Salt_and_pepper_noise(image):\n",
    "    count = 0\n",
    "    lastMedian = image\n",
    "    median = cv2.medianBlur(image, 3)\n",
    "    while not np.array_equal(lastMedian, median):\n",
    "        zeroed = np.invert(np.logical_and(median, image))\n",
    "        image[zeroed] = 0\n",
    "\n",
    "        count = count + 1\n",
    "        if count > 70:\n",
    "            break\n",
    "        lastMedian = median\n",
    "        median = cv2.medianBlur(image, 3)\n",
    "    return image\n",
    "\n",
    "#find the significant contour\n",
    "def Contour(image):\n",
    "    contours, hierarchy = cv2.findContours(image,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    level1Meta = []\n",
    "    for contourIndex, tupl in enumerate(hierarchy[0]):\n",
    "        if tupl[3] == -1:\n",
    "            tupl = np.insert(tupl.copy(), 0, [contourIndex])\n",
    "            level1Meta.append(tupl)\n",
    "            \n",
    "    contoursWithArea = []\n",
    "    for tupl in level1Meta:\n",
    "        contourIndex = tupl[0]\n",
    "        contour = contours[contourIndex]\n",
    "        area = cv2.contourArea(contour)\n",
    "        contoursWithArea.append([contour, area, contourIndex])\n",
    "    contoursWithArea.sort(key=lambda meta: meta[1], reverse=True)\n",
    "    largestContour = contoursWithArea[0][0]\n",
    "    return largestContour\n",
    "\n",
    "def resize(img):\n",
    "    return cv2.resize(img,(240,320))\n",
    "    \n",
    "from PIL import Image\n",
    "import PIL.ImageOps\n",
    "\n",
    "i=0\n",
    "input_images = glob('./inputs/*.jpg')\n",
    "\n",
    "for i in range(len(input_images)):\n",
    "    input_image = cv2.imread(input_images[i])\n",
    "    input_image = resize(input_image)\n",
    "    input_image = input_image[:,:,::-1]\n",
    "\n",
    "    #perform gaussion blur\n",
    "    blur = cv2.GaussianBlur(input_image, (5, 5), 0)\n",
    "    blur = blur.astype(np.float32) / 255.0\n",
    "\n",
    "    #use the model.yml file to perform edge detection (pre-trained)\n",
    "    edgeDetector = cv2.ximgproc.createStructuredEdgeDetection(\"model.yml\")\n",
    "    edges = edgeDetector.detectEdges(blur) * 255.0\n",
    "    edges_8u = np.asarray(edges, np.uint8)\n",
    "    Salt_and_pepper_noise(edges_8u)\n",
    "\n",
    "    contour = Contour(edges_8u)\n",
    "\n",
    "    # Draw the contour on the original image\n",
    "    contourImg = np.copy(input_image)\n",
    "    cv2.drawContours(contourImg, [contour], 0, (0, 255, 0), 2, cv2.LINE_AA, maxLevel=1)\n",
    "\n",
    "    #Generate trimap\n",
    "    mask = np.zeros_like(edges_8u)\n",
    "    cv2.fillPoly(mask, [contour], 255)\n",
    "\n",
    "    # calculate sure foreground area by dilating the mask\n",
    "    mapFg = cv2.erode(mask, np.ones((5, 5), np.uint8), iterations=10)\n",
    "\n",
    "    trimap = np.copy(mask)\n",
    "    trimap[mask == 0] = cv2.GC_BGD\n",
    "    trimap[mask == 255] = cv2.GC_PR_BGD\n",
    "    trimap[mapFg == 255] = cv2.GC_FGD\n",
    "\n",
    "    # visualize trimap\n",
    "    trimap_print = np.copy(trimap)\n",
    "    trimap_print[trimap_print == cv2.GC_PR_BGD] = 128\n",
    "    trimap_print[trimap_print == cv2.GC_FGD] = 255\n",
    "\n",
    "    mask_path = \"./mask_images/\"\n",
    "    trimap_path = \"./trimap_images/\"\n",
    "    target_path = \"./target_images/\"\n",
    "\n",
    "    try:\n",
    "        os.stat(trimap_path)\n",
    "    except:\n",
    "        os.mkdir(trimap_path)\n",
    "\n",
    "    try:\n",
    "        os.stat(target_path)\n",
    "    except:\n",
    "        os.mkdir(target_path)\n",
    "\n",
    "    try:\n",
    "        os.stat(mask_path)\n",
    "    except:\n",
    "        os.mkdir(mask_path)  \n",
    "\n",
    "    cv2.imwrite(trimap_path + 'trimap_' + str(i) +'.png', trimap_print)\n",
    "\n",
    "    # run grabcut\n",
    "    bgdModel = np.zeros((1, 65), np.float64)\n",
    "    fgdModel = np.zeros((1, 65), np.float64)\n",
    "    rect = (0, 0, mask.shape[0] - 1, mask.shape[1] - 1)\n",
    "    cv2.grabCut(input_image, trimap, rect, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_MASK)\n",
    "\n",
    "    # create mask again\n",
    "    mask2 = np.where((trimap == cv2.GC_FGD) | (trimap == cv2.GC_PR_FGD),255,0).astype('uint8')\n",
    "    cv2.imwrite(mask_path + 'mask_' + str(i) +'.png', mask2)\n",
    "\n",
    "    # estimate alpha from image and trimap\n",
    "    alpha = mask2\n",
    "    alpha = cv2.resize(alpha,(input_image.shape[1],input_image.shape[0]))\n",
    "    alpha = alpha.astype(float)/255\n",
    "    ones_for_alpha = np.ones((alpha.shape[0],alpha.shape[1]))\n",
    "\n",
    "\n",
    "\n",
    "    # make gray background\n",
    "    background_image = cv2.imread(input_images[3])\n",
    "    background_image = cv2.resize(background_image, (input_image.shape[1],input_image.shape[0]), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    background_image =  (ones_for_alpha - alpha)[:,:,np.newaxis] * background_image\n",
    "    background_image = background_image.astype('uint8')\n",
    "    cv2.imwrite( 'back.png', background_image)\n",
    "\n",
    "\n",
    "    # estimate foreground from image and alpha\n",
    "    foreground = (input_image * alpha[:,:,np.newaxis])[:,:,::-1]\n",
    "    foreground = foreground.astype('uint8')\n",
    "    cv2.imwrite( 'front.png', foreground)\n",
    "\n",
    "    # blend foreground with background and alpha, less color bleeding\n",
    "    out_image = cv2.add(foreground, background_image)\n",
    "    cv2.imwrite(target_path + 'target_' + str(i) +'.png', out_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
