#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
\usepackage{graphicx}





\usepackage[html,dvipsnames]{xcolor}




\setlength{\textwidth}{6.5in}
\setlength{\textheight}{9.0in}
\headheight=0.5in
\topmargin=-0.75in
\oddsidemargin= 0.0in
\evensidemargin=-0.25in


 




\markright{{\bf EE599 - \copyright B. Franzke - Fall 2020} }


\title{\bf EE599 Deep Learning -- Initial Project Proposal}
\author{\copyright  B. Franzke}
\end_preamble
\use_default_options false
\maintain_unincluded_children false
\language english
\language_package none
\inputencoding iso8859-15
\fontencoding default
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize 11
\spacing single
\use_hyperref true
\pdf_title "EE599ProjectSummary"
\pdf_author "BrandonFranzke"
\pdf_bookmarks false
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder false
\pdf_colorlinks false
\pdf_backref section
\pdf_pdfusetitle false
\pdf_quoted_options "pdftex,bookmarks,colorlinks,citecolor=green,filecolor=Orange,linkcolor=blue,urlcolor=BrickRed,pdftex"
\papersize default
\use_geometry false
\use_package amsmath 2
\use_package amssymb 2
\use_package cancel 0
\use_package esint 1
\use_package mathdots 0
\use_package mathtools 0
\use_package mhchem 0
\use_package stackrel 0
\use_package stmaryrd 0
\use_package undertilde 0
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
maketitle
\end_layout

\end_inset


\end_layout

\begin_layout Paragraph
Project Title:
\end_layout

\begin_layout Standard
Realtime Background Replacement and Super Resolution for Video Conferencing
 Applications
\end_layout

\begin_layout Paragraph
Project Team:
\end_layout

\begin_layout Standard
Adityan Jothi, Aditi Hoskere Deepak, Srujana Subramanya
\end_layout

\begin_layout Paragraph
Project Summary:
\end_layout

\begin_layout Standard
In this project we propose to generate photo-realistic background replaced
 images in real-time along with super resolution for video conference applicatio
ns using GANs.
 We will collect data from Youtube-8M dataset and use some Zoom call recordings
 amongst the group.
 The project will involve experimenting on different GAN architectures and
 loss functions for Super Resolution and Background Replacement.
 A successful outcome would be to produce a 4-5 minute video call that is
 photorealistic with improved image quality.
\end_layout

\begin_layout Paragraph
Data Needs and Acquisition Plan:
\end_layout

\begin_layout Standard
We would be using videos similar to teleconferencing calls, interviews,
 Twitch game streams, and more from the Youtube-8M dataset as a baseline
 and include several recorded videos of Zoom calls amongst the group.
 For the dataset generated by us, we would build an auto annotation tool
 using segmentation model to isolate subject efficiently in the video clips
 for labeling.
 The dataset is available open-source mapped to YouTube videos that can
 be downloaded using the youtube downloader tool.
\end_layout

\begin_layout Paragraph
Primary References and Codebase:
\end_layout

\begin_layout Standard
We propose to build on the approach used in 
\end_layout

\begin_layout Itemize
Olof Mogren, 
\begin_inset Quotes eld
\end_inset


\begin_inset CommandInset href
LatexCommand href
name "Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network"
target "https://arxiv.org/pdf/1609.04802.pdf"
literal "false"

\end_inset

,
\begin_inset Quotes erd
\end_inset

 Computer Vision and Pattern Recognition (CVPR).
 
\end_layout

\begin_layout Itemize
Architecture: 
\begin_inset CommandInset href
LatexCommand href
name "U-Net paper"
target "https://arxiv.org/pdf/1505.04597.pdf"
literal "false"

\end_inset


\end_layout

\begin_layout Itemize
GitHub codebases: 
\begin_inset CommandInset href
LatexCommand href
name "U-Net GAN Code"
target "https://github.com/eti-p-doray/unet-gan-matting"
literal "false"

\end_inset

, 
\begin_inset CommandInset href
LatexCommand href
name "Fast-SRGAN Code"
target "https://github.com/HasnainRaz/Fast-SRGAN"
literal "false"

\end_inset


\end_layout

\begin_layout Paragraph
Architecture Investigation Plan:
\end_layout

\begin_layout Standard
We plan to use U-Net with GANs for Background Replacement and SRGAN for
 Super Resolution.
 Furthermore we would try to construct a model that achieves both these
 tasks as a single end-to-end learning task and explore various methods
 to improve the quality of background-replaced super resolution images generated
 by the model.
\end_layout

\begin_layout Paragraph
Estimated Compute Needs:
\end_layout

\begin_layout Standard
Based on the data set size in the above paper and the benchmarks in this
 original U-Net paper, we estimate that one training run for our initial
 U-Net GAN architecture will take 20 hours on a single Nvidia V100 GPU,
 which is the GPU resource in the AWS p3.2xlarge instance.
 With spot pricinsg, which is roughly 1$ per hour, we can expect 20$ per
 training run.
 For the SRGAN architecture we estimate that one training run will take
 15 hours; so we estimate 15$ per run.
 We expect to do several experiments to combine these two tasks into one
 unified architecture with different loss functions, hyperparameters.
 We estimate that this will cost approximate 40$.
 In addition, we expect to do approximately 4 full runs which brings our
 total estimated computing cost to roughly 250$.
 Pooling our resources, we expect to be about 100$ short of this value.
\end_layout

\begin_layout Paragraph
Team Roles:
\end_layout

\begin_layout Standard
The following is the rough breakdown of roles and responsibilities we plan
 for our team:
\end_layout

\begin_layout Itemize
Adityan: Super Resolution GAN, Model Compression and Acceleration
\end_layout

\begin_layout Itemize
Srujana: Background Replacement U-Net, GAN and Image Matting
\end_layout

\begin_layout Itemize
Aditi: Background Matting Model using GANs, Auto-annotation model (Data
 collection and cleaning) 
\end_layout

\begin_layout Standard
All team members will work on the final presentation, slides, and report.
\end_layout

\begin_layout Paragraph
Requested Mentor with Rationale:
\end_layout

\begin_layout Standard
We request Professor Franzke to be our team mentor because he has expertise
 in Computer Vision and GANs.
 Oliver is our second choice because of his expertise in Computer Vision.
 We have a good idea of what we want to do and have a good starting point
 from the paper and codebase, so we are flexible regarding our mentor assignment.
 
\end_layout

\end_body
\end_document
