%% LyX 2.3.5.2 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[11pt]{article}
\usepackage[latin9]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{caption}
\usepackage{graphicx}
\captionsetup[figure]{font=small}
\usepackage[unicode=true,
 bookmarks=false,
 breaklinks=false,pdfborder={0 0 1},backref=section,colorlinks=false]
 {hyperref}
\hypersetup{pdftitle={EE599ProjectSummary},
 pdfauthor={BrandonFranzke},
 pdftex,bookmarks,colorlinks,citecolor=green,filecolor=Orange,linkcolor=blue,urlcolor=BrickRed,pdftex}

\makeatletter
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
\usepackage{graphicx}





\usepackage[html,dvipsnames]{xcolor}




\setlength{\textwidth}{6.5in}
\setlength{\textheight}{9.0in}
\headheight=0.5in
\topmargin=-0.75in
\oddsidemargin= 0.0in
\evensidemargin=-0.25in


 




\markright{{\bf EE599 - \copyright B. Franzke - Fall 2020} }


\title{\bf EE599 Deep Learning -- Initial Project Proposal}
\author{\copyright  B. Franzke}

\makeatother

\begin{document}
\maketitle

\paragraph{Project Title:}

Realtime Background Replacement and Super Resolution for Video Conferencing
Applications

\paragraph{Project Team:}

Adityan Jothi, Aditi Hoskere Deepak, Srujana Subramanya

\paragraph{Project Summary:}

In this project we propose to generate photo-realistic background
replaced images in real-time along with super resolution for video
conference applications using GANs. We will collect data from YouTube/Kaggle dataset videos with single person speaker in the frame. The project
will involve experimenting on different GAN architectures and loss
functions for Super Resolution and Background Replacement. A successful
outcome would be to produce a 4-5 minute video call that is photorealistic
with improved image quality.


    \begin{figure}[htp]
    \centering
    \includegraphics[width=17cm]{block_diagram.PNG}
    \caption{Block Diagram}
    \includegraphics[width=13cm]{WhatsApp Image 2020-11-24 at 7.55.24 PM.jpeg}
    \caption{Super Resolution Model Architecture}
    \end{figure}


\paragraph{Data Needs and Acquisition Plan:}

We would be using videos similar to teleconferencing calls, interviews,
Twitch game streams, Kaggle dataset and more from the Youtube video dataset as a baseline
and include several recorded videos of Zoom calls amongst the group.
For the dataset generated by us, we would build an auto annotation
tool using segmentation model to isolate subject efficiently in the
video clips for labeling. The dataset is available open-source mapped
to YouTube videos that can be downloaded using the youtube downloader
tool. Upon successful masking of the background image, we will be replacing
the background mask with a new background image. The dataset for these
background images is acquired by Kaggle datasets.

\paragraph{Primary References and Codebase:}

We propose to build on the approach used in 
\begin{itemize}
\item Olof Mogren, ``\href{https://arxiv.org/pdf/1609.04802.pdf}{Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network},''
Computer Vision and Pattern Recognition (CVPR). 
\item Architecture: \href{https://arxiv.org/pdf/1505.04597.pdf}{U-Net paper},
\href{https://openaccess.thecvf.com/content_cvpr_2017_workshops/w12/papers/Lim_Enhanced_Deep_Residual_CVPR_2017_paper.pdf}{EDSR paper}
\item GitHub codebases: \href{https://github.com/eti-p-doray/unet-gan-matting}{U-Net GAN Code}, \href{https://github.com/thstkdgus35/EDSR-PyTorch}{EDSR Code},
\href{https://github.com/HasnainRaz/Fast-SRGAN}{Fast-SRGAN Code}
\item Dataset: \href{https://www.kaggle.com/balraj98/stanford-background-dataset?select=image}{Background Images Dataset}, \href{https://www.kaggle.com/toxtli/video-blooper-dataset-for-automatic-video-editing}{Video Dataset}
\end{itemize}

\paragraph{Architecture Investigation Plan:}

We plan to use U-Net with GANs for Background Replacement and SRGAN
for Super Resolution. Super resolution is performed on the background replaced image to improve quality of the image as a whole. Furthermore we would
try to construct a model that achieves both these tasks as a single end-to-end 
learning task and explore various methods to improve the quality of 
background-replaced super resolution images generated by the model.

\paragraph{Estimated Compute Needs:}

Based on the data set size in the above paper and the benchmarks in
this original U-Net paper, we estimate that one training run for our
initial U-Net GAN architecture will take 20 hours on a single Nvidia
V100 GPU, which is the GPU resource in the AWS p3.2xlarge instance.
With spot pricing, which is roughly 1\$ per hour, we can expect 20\$
per training run. For the SRGAN architecture we estimate that one
training run will take 15 hours; so we estimate 15\$ per run. We expect
to do several experiments to combine these two tasks into one unified
architecture with different loss functions, hyperparameters. We estimate
that this will cost approximate 40\$. In addition, we expect to do
approximately 4 full runs which brings our total estimated computing
cost to roughly 250\$. Pooling our resources, we expect to be about
100\$ short of this value.

\paragraph{Team Roles:}

The following is the rough breakdown of roles and responsibilities
we plan for our team:
\begin{itemize}
\item Adityan: Super Resolution GAN,Model Acceleration(Pruning, Quantization to decrease inference time)
\item Srujana: Background Replacement U-Net, GAN and Image Matting
\item Aditi: Background Matting Model using GANs, Auto-annotation model
(Data collection and cleaning) 
\end{itemize}
All team members will work on the final presentation, slides, and
report.

\paragraph{Requested Mentor with Rationale:}

We request Professor Franzke to be our team mentor because he has
expertise in Computer Vision and GANs. Oliver is our second choice
because of his expertise in Computer Vision. We have a good idea of
what we want to do and have a good starting point from the paper and
codebase, so we are flexible regarding our mentor assignment. 
\end{document}
